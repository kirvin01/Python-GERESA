{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      6\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m../../\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mclases\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbd\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconexion2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MyDatabase2\n\u001b[32m      8\u001b[39m conn = MyDatabase2()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\www\\python\\Python-GERESA\\modulos\\pruebas\\../..\\clases\\bd\\conexion2.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdecouple\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsycopg2\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsycopg2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Error\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsycopg2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ISOLATION_LEVEL_AUTOCOMMIT\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob as gb\n",
    "import sys\n",
    "sys.path.insert(0, \"../../\")\n",
    "from clases.bd.conexion2 import MyDatabase2\n",
    "conn = MyDatabase2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'd:\\\\Irvin\\\\Irvin\\\\Python\\\\data\\\\2023\\\\csv\\\\02-2023.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ruta_datos \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../../data/2023/csv/02-2023.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m csv\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruta_datos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mISO-8859-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m csv\u001b[38;5;241m=\u001b[39mcsv[csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPeso\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m999\u001b[39m]\n\u001b[0;32m      5\u001b[0m result \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPeso\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Irvin\\Irvin\\Python\\Python-GERESA\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Irvin\\Irvin\\Python\\Python-GERESA\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\Irvin\\Irvin\\Python\\Python-GERESA\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Irvin\\Irvin\\Python\\Python-GERESA\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32md:\\Irvin\\Irvin\\Python\\Python-GERESA\\venv\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'd:\\\\Irvin\\\\Irvin\\\\Python\\\\data\\\\2023\\\\csv\\\\02-2023.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ruta_datos = os.path.abspath(\"../../../data/2023/csv/02-2023.csv\")\n",
    "csv=pd.read_csv(ruta_datos, encoding=\"ISO-8859-1\")\n",
    "csv=csv[csv['Peso']>999]\n",
    "\n",
    "result = csv.groupby('Peso').size().reset_index(name='count')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consulta_C0010(conn):  \n",
    "    sql = conn.df(\"\"\"SELECT *\n",
    "FROM( \n",
    "   SELECT nt.fecha_atencion, nt.id_paciente , nt.id_cita, mp2.id_tipo_documento ,mp2.numero_documento , nt.fecha_atencion,nt.codigo_item,mhcc.descripcion_item,nt.id_ups,mhu.descripcion_ups,concat(mr.nombres_registrador,' ',mr.apellido_paterno_registrador,' ',mr.apellido_materno_registrador )AS registrador ,concat(mp.nombres_personal,' ',mp.apellido_paterno_personal,' ',mp.apellido_materno_personal) AS personal, nt.id_otra_condicion , \n",
    " max(CASE  WHEN nt.id_correlativo_lab='1' THEN nt.valor_lab ELSE null END ) AS Lab1,\n",
    " max(CASE  WHEN nt.id_correlativo_lab='2' THEN nt.valor_lab ELSE null END ) AS Lab2,\n",
    " max(CASE  WHEN nt.id_correlativo_lab='3' THEN nt.valor_lab ELSE null END ) AS Lab3\n",
    "FROM maestros.nominal_trama nt\n",
    "INNER JOIN maestros.maestro_paciente mp2 ON nt.id_paciente=mp2.id_paciente \n",
    "left JOIN maestros.maestro_his_cie_cpms mhcc ON nt.codigo_item =mhcc.codigo_item \n",
    "LEFT JOIN maestros.maestro_his_ups mhu ON mhu.id_ups = nt.id_ups \n",
    "LEFT JOIN maestros.maestro_registrador mr ON mr.id_registrador =nt.id_registrador \n",
    "LEFT JOIN maestros.maestro_personal mp ON mp.id_personal =nt.id_personal \n",
    "WHERE nt.codigo_item ='C0010' AND nt.fecha_atencion BETWEEN '2023-06-01' AND '2023-07-31'  AND mp2.id_tipo_documento =1 AND nt.id_otra_condicion =1\n",
    "GROUP BY  nt.id_paciente , nt.id_cita, mp2.id_tipo_documento ,mp2.numero_documento, nt.fecha_atencion,nt.codigo_item,mhcc.descripcion_item,nt.id_ups,mhu.descripcion_ups,mr.nombres_registrador,mr.apellido_paterno_registrador,mr.apellido_materno_registrador , mp.nombres_personal,mp.apellido_paterno_personal,mp.apellido_materno_personal,nt.id_otra_condicion\n",
    ") AS t WHERE Lab1='ALI' AND Lab2='GL'   \"\"\")\n",
    "    \n",
    "    sql = sql.rename(columns={'numero_documento': 'dni'})\n",
    "    sql['dni'] = sql['dni'].astype(int)\n",
    "    \n",
    "    \n",
    "    return sql\n",
    "df_dx=consulta_C0010(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consulta_sql(conn):  \n",
    "\n",
    "    sql = conn.df(\"\"\" SELECT * FROM nominal_trama nt WHERE nt.fecha_atencion  BETWEEN '2023-08-01' AND '2023-08-15'  \"\"\")\n",
    "    return sql\n",
    "df_1=consulta_sql(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_1\n",
    "# Eliminar duplicados\n",
    "df_no_duplicates = df.drop_duplicates(subset=['id_paciente', 'codigo_item','fecha_atencion','id_correlativo_lab'])\n",
    "\n",
    "# Pivoteo dinámico usando pandas\n",
    "pivoted_df = df_no_duplicates.pivot(index=['id_cita','id_paciente','fecha_atencion','codigo_item', 'tipo_diagnostico'],\n",
    "                                     columns='id_correlativo_lab',\n",
    "                                     values='valor_lab').reset_index()\n",
    "print(pivoted_df)\n",
    "pivoted_df.to_excel('demo.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consulta_sql(conn):  \n",
    "\n",
    "    sql = conn.df(\"\"\" SELECT * FROM maestros.maestro_his_ubigeo_inei_reniec \"\"\")\n",
    "    sql = sql.rename(columns={'id_ubigueo_inei': 'ubigeo'})\n",
    "    return sql\n",
    "ubigeo=consulta_sql(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>NORKA - NIÑO</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Irvin\\Irvin\\Python\\Python-GERESA\\modulos\\pruebas\\../..\\clases\\bd\\conexion2.py:42: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  s = pd.read_sql(sql, con=self.conn)\n"
     ]
    }
   ],
   "source": [
    "#archivo_excel = \"nominal_ninos.xlsx\"\n",
    "doc=\"SELLO ESTADISTICA/Niños agos a nov 6 a 11 meses\"\n",
    "archivo_excel = \"\"\"%s.xlsx\"\"\"%doc\n",
    "\n",
    "df = pd.read_excel(archivo_excel,sheet_name=0)\n",
    "#df['ubigeo'] = df['ubigeo'].astype(str).str.zfill(6)\n",
    "\n",
    "df=df.drop_duplicates(subset=['Nro_Doc'])\n",
    "\n",
    "df = df.rename(columns={'Nro_Doc': 'nro_doc'})\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "# Convierte los DNIs a una lista\n",
    "dnis = df['nro_doc'].tolist()\n",
    "# Convierte los DNIs en una cadena separada por comas para usar en la consulta SQL\n",
    "numeros_dni_str = ','.join([\"'\" + str(dni) + \"'\" for dni in dnis])\n",
    "\n",
    "# Crea la consulta SQL con una cláusula WHERE para filtrar por los DNIs\n",
    "# Consulta SQL con los números de DNI\n",
    "sql = f\"\"\"SELECT t.numero_documento as nro_doc,t.rn as his  FROM (\n",
    "SELECT\n",
    "   nt.numero_documento, \n",
    "    ROW_NUMBER() OVER (PARTITION BY nt.numero_documento ORDER BY nt.fecha_atencion ) AS rn\n",
    "FROM\n",
    "    maestros.nominal_trama2 nt\n",
    "WHERE\n",
    "    nt.codigo_item = 'C0010'\n",
    "    AND nt.lab1 = 'ALI'\n",
    "    AND nt.lab2 = 'GL'\n",
    "    AND nt.mes in(8,9,10,11,12)\n",
    "    AND nt.numero_documento IN ({numeros_dni_str}) )t WHERE t.rn=1 \"\"\" \n",
    "      \n",
    "ninio=conn.df(sql)\n",
    "\n",
    "#######################################################################################################\n",
    "\n",
    "ninio['nro_doc'] = ninio['nro_doc'].astype(int)\n",
    "\n",
    "df=df.merge(ninio, how='left', on=['nro_doc'])\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "#archivo_excel = \"nominal_ninos.xlsx\"\n",
    "doc=\"SELLO ESTADISTICA/NOMINA DE NIÑOS Y GESTANTES CONSOLIDADO 14.12.23\"\n",
    "archivo_excel = \"\"\"%s.xlsx\"\"\"%doc\n",
    "\n",
    "df2 = pd.read_excel(archivo_excel,sheet_name=0)\n",
    "df2=df2.drop_duplicates(subset=['N° DNI'])\n",
    "\n",
    "df2 = df2.rename(columns={'N° DNI': 'nro_doc'})\n",
    "df2 = df2.drop(['PROVINCIA', 'DISTRITO','Nombre y Apellidos','FECHA DE NACIMIENTO','EDAD'\t], axis=1)\n",
    "df2['numerador'] = 1\n",
    "\n",
    "df=df.merge(df2, how='left', on=['nro_doc'])\n",
    "\n",
    "df.to_excel(\"SELLO ESTADISTICA/ESTADISTICA/Niños agos a nov 6 a 11 meses_Final.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>NORKA - GESTANTE</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Irvin\\Irvin\\Python\\Python-GERESA\\modulos\\pruebas\\../..\\clases\\bd\\conexion2.py:42: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  s = pd.read_sql(sql, con=self.conn)\n"
     ]
    }
   ],
   "source": [
    "#archivo_excel = \"nominal_ninos.xlsx\"\n",
    "doc=\"SELLO ESTADISTICA/nomina gestante agost a noviembre\"\n",
    "archivo_excel = \"\"\"%s.xlsx\"\"\"%doc\n",
    "\n",
    "df = pd.read_excel(archivo_excel,sheet_name=0)\n",
    "#df['ubigeo'] = df['ubigeo'].astype(str).str.zfill(6)\n",
    "\n",
    "df=df.drop_duplicates(subset=['Nro_Doc'])\n",
    "df = df.rename(columns={'Nro_Doc': 'nro_doc'})\n",
    "##############################################################################################\n",
    "\n",
    "# Convierte los DNIs a una lista\n",
    "dnis = df['nro_doc'].tolist()\n",
    "# Convierte los DNIs en una cadena separada por comas para usar en la consulta SQL\n",
    "numeros_dni_str = ','.join([\"'\" + str(dni) + \"'\" for dni in dnis])\n",
    "\n",
    "# Crea la consulta SQL con una cláusula WHERE para filtrar por los DNIs\n",
    "# Consulta SQL con los números de DNI\n",
    "sql = f\"\"\"SELECT t.numero_documento as nro_doc,t.rn as his FROM (\n",
    "SELECT\n",
    "   nt.numero_documento, nt.codigo_item , nt.id_otra_condicion, nt.lab1 , nt.lab2 ,\n",
    "    ROW_NUMBER() OVER (PARTITION BY nt.numero_documento ORDER BY nt.fecha_atencion ) AS rn\n",
    "FROM\n",
    "    maestros.nominal_trama2 nt  \n",
    "WHERE\n",
    "    nt.codigo_item = 'C0010'\n",
    " AND nt.lab1 = 'ALI'\n",
    "    AND nt.lab2 = 'GL'\n",
    "    AND nt.mes in(8,9,10,11,12)\n",
    "    AND nt.anio =2023\n",
    "    AND nt.id_otra_condicion =1\n",
    "    AND nt.numero_documento in ({numeros_dni_str})   \n",
    "    ) t WHERE t.rn=1 \"\"\"       \n",
    "\n",
    "gestante=conn.df(sql)\n",
    "\n",
    "gestante['nro_doc'] = gestante['nro_doc'].astype(int)\n",
    "\n",
    "df=df.merge(gestante, how='left', on=['nro_doc'])\n",
    "\n",
    "#######################################################################################################\n",
    "\n",
    "#archivo_excel = \"nominal_ninos.xlsx\"\n",
    "doc=\"SELLO ESTADISTICA/NOMINA DE NIÑOS Y GESTANTES CONSOLIDADO 14.12.23\"\n",
    "archivo_excel = \"\"\"%s.xlsx\"\"\"%doc\n",
    "\n",
    "df2 = pd.read_excel(archivo_excel,sheet_name=1)\n",
    "df2 = df2.rename(columns={'N° DNI': 'nro_doc'})\n",
    "df2=df2.drop_duplicates(subset=['nro_doc'])\n",
    "\n",
    "columnas_a_conservar = ['nro_doc', ]\n",
    "# Eliminar todas las columnas excepto las especificadas en columnas_a_conservar\n",
    "df2.drop(df2.columns.difference(columnas_a_conservar), axis=1, inplace=True)\n",
    "\n",
    "df2['numerador'] = 1\n",
    "\n",
    "df=df.merge(df2, how='left', on=['nro_doc'])\n",
    "\n",
    "df.to_excel(\"SELLO ESTADISTICA/ESTADISTICA/nomina gestante agost a noviembre.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_excel(archivo_excel,sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko\n",
    "\n",
    "# Configuramos los datos de conexión\n",
    "#host = \"sftp://carga.minsa.gob.pe\"\n",
    "host = \"181.177.250.128\"\n",
    "port = 22\n",
    "username = \"usr_dhr_008\"\n",
    "password = \"X3veTg8z62R74J\"\n",
    "\n",
    "# Creamos el objeto SSHClient\n",
    "client = paramiko.SSHClient()\n",
    "client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "client.connect(host, port, username, password)\n",
    "\n",
    "# Creamos el objeto SFTPClient\n",
    "sftp = client.open_sftp()\n",
    "\n",
    "# Descargamos el archivo\n",
    "filename = \"/data_cvs_nominal/2023/\"\n",
    "local_path = \"C:/Users/IRVIN/Downloads/his/\"\n",
    "sftp.get(filename, local_path)\n",
    "\n",
    "# Cerramos la conexión\n",
    "sftp.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko\n",
    "import os\n",
    "\n",
    "def download_files_sftp(hostname, port, username, password, remote_path, local_path):\n",
    "    try:\n",
    "        # Crear el objeto SSHClient\n",
    "        client = paramiko.SSHClient()\n",
    "        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "\n",
    "        # Conectar al servidor SFTP\n",
    "        client.connect(hostname, port, username, password)\n",
    "\n",
    "        # Crear el objeto SFTPClient\n",
    "        sftp = client.open_sftp()\n",
    "\n",
    "        # Verificar si la ruta local existe, si no, crearla\n",
    "        if not os.path.exists(local_path):\n",
    "            os.makedirs(local_path)\n",
    "\n",
    "        # Listar archivos remotos en el directorio\n",
    "        remote_files = sftp.listdir(remote_path)\n",
    "\n",
    "        # Descargar cada archivo remoto\n",
    "        for remote_file in remote_files:\n",
    "            remote_file_path = os.path.join(remote_path, remote_file)\n",
    "            local_file_path = os.path.join(local_path, remote_file)\n",
    "            sftp.get(remote_file_path, local_file_path)\n",
    "\n",
    "        print(\"Descarga completa.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la descarga: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # Cerrar la conexión\n",
    "        if sftp:\n",
    "            sftp.close()\n",
    "        client.close()\n",
    "\n",
    "# Configuramos los datos de conexión\n",
    "host = \"181.177.250.128\"\n",
    "port = 22\n",
    "username = \"usr_dhr_008\"\n",
    "password = \"X3veTg8z62R74J\"\n",
    "\n",
    "# Ruta remota y local\n",
    "remote_directory = \"/data_cvs_nominal/2023/\"\n",
    "local_directory = \"C:/Users/IRVIN/Downloads/his/\"\n",
    "\n",
    "# Llamar a la función para descargar archivos\n",
    "download_files_sftp(host, port, username, password, remote_directory, local_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "archivo_excel = 'D:\\Irvin\\Anemia\\Capacitacion\\Curso Procesamiento Bases His Cusco-Puno-Piura\\Materiales de consulta\\RENAES - Taller.xlsx'\n",
    "datos = pd.read_excel(archivo_excel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.columns = datos.columns.str.lower()\n",
    "conn.insert_df(datos, 'renaes_altitud_eess','public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.7\n",
      "postgres\n",
      "213141\n",
      "irvin_hisminsa\n",
      "5432\n"
     ]
    }
   ],
   "source": [
    "from decouple import config\n",
    "print (config('DB_HOST'))\n",
    "print (config('DB_USER'))\n",
    "print (config('DB_PASSWORD'))\n",
    "print (config('DB_DATABASE'))\n",
    "print (config('DB_PORT'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IRVIN\\AppData\\Local\\Temp\\ipykernel_23208\\3659028730.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexion exitosa con la Base de datos:irvin_hisminsa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob as gb\n",
    "import sys\n",
    "sys.path.insert(0, \"../../\")\n",
    "from clases.bd.conexion2 import MyDatabase2\n",
    "conn = MyDatabase2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'd:\\\\Irvin\\\\Irvin\\\\Python\\\\data\\\\2023\\\\csv\\\\02-2023.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ruta_datos \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../../data/2023/csv/02-2023.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m csv\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruta_datos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mISO-8859-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m csv\u001b[38;5;241m=\u001b[39mcsv[csv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPeso\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m999\u001b[39m]\n\u001b[0;32m      5\u001b[0m result \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPeso\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Irvin\\Irvin\\Python\\Python-GERESA\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Irvin\\Irvin\\Python\\Python-GERESA\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\Irvin\\Irvin\\Python\\Python-GERESA\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Irvin\\Irvin\\Python\\Python-GERESA\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32md:\\Irvin\\Irvin\\Python\\Python-GERESA\\venv\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'd:\\\\Irvin\\\\Irvin\\\\Python\\\\data\\\\2023\\\\csv\\\\02-2023.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ruta_datos = os.path.abspath(\"../../../data/2023/csv/02-2023.csv\")\n",
    "csv=pd.read_csv(ruta_datos, encoding=\"ISO-8859-1\")\n",
    "csv=csv[csv['Peso']>999]\n",
    "\n",
    "result = csv.groupby('Peso').size().reset_index(name='count')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consulta_C0010(conn):  \n",
    "    sql = conn.df(\"\"\"SELECT *\n",
    "FROM( \n",
    "   SELECT nt.fecha_atencion, nt.id_paciente , nt.id_cita, mp2.id_tipo_documento ,mp2.numero_documento , nt.fecha_atencion,nt.codigo_item,mhcc.descripcion_item,nt.id_ups,mhu.descripcion_ups,concat(mr.nombres_registrador,' ',mr.apellido_paterno_registrador,' ',mr.apellido_materno_registrador )AS registrador ,concat(mp.nombres_personal,' ',mp.apellido_paterno_personal,' ',mp.apellido_materno_personal) AS personal, nt.id_otra_condicion , \n",
    " max(CASE  WHEN nt.id_correlativo_lab='1' THEN nt.valor_lab ELSE null END ) AS Lab1,\n",
    " max(CASE  WHEN nt.id_correlativo_lab='2' THEN nt.valor_lab ELSE null END ) AS Lab2,\n",
    " max(CASE  WHEN nt.id_correlativo_lab='3' THEN nt.valor_lab ELSE null END ) AS Lab3\n",
    "FROM maestros.nominal_trama nt\n",
    "INNER JOIN maestros.maestro_paciente mp2 ON nt.id_paciente=mp2.id_paciente \n",
    "left JOIN maestros.maestro_his_cie_cpms mhcc ON nt.codigo_item =mhcc.codigo_item \n",
    "LEFT JOIN maestros.maestro_his_ups mhu ON mhu.id_ups = nt.id_ups \n",
    "LEFT JOIN maestros.maestro_registrador mr ON mr.id_registrador =nt.id_registrador \n",
    "LEFT JOIN maestros.maestro_personal mp ON mp.id_personal =nt.id_personal \n",
    "WHERE nt.codigo_item ='C0010' AND nt.fecha_atencion BETWEEN '2023-06-01' AND '2023-07-31'  AND mp2.id_tipo_documento =1 AND nt.id_otra_condicion =1\n",
    "GROUP BY  nt.id_paciente , nt.id_cita, mp2.id_tipo_documento ,mp2.numero_documento, nt.fecha_atencion,nt.codigo_item,mhcc.descripcion_item,nt.id_ups,mhu.descripcion_ups,mr.nombres_registrador,mr.apellido_paterno_registrador,mr.apellido_materno_registrador , mp.nombres_personal,mp.apellido_paterno_personal,mp.apellido_materno_personal,nt.id_otra_condicion\n",
    ") AS t WHERE Lab1='ALI' AND Lab2='GL'   \"\"\")\n",
    "    \n",
    "    sql = sql.rename(columns={'numero_documento': 'dni'})\n",
    "    sql['dni'] = sql['dni'].astype(int)\n",
    "    \n",
    "    \n",
    "    return sql\n",
    "df_dx=consulta_C0010(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consulta_sql(conn):  \n",
    "\n",
    "    sql = conn.df(\"\"\" SELECT * FROM nominal_trama nt WHERE nt.fecha_atencion  BETWEEN '2023-08-01' AND '2023-08-15'  \"\"\")\n",
    "    return sql\n",
    "df_1=consulta_sql(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_1\n",
    "# Eliminar duplicados\n",
    "df_no_duplicates = df.drop_duplicates(subset=['id_paciente', 'codigo_item','fecha_atencion','id_correlativo_lab'])\n",
    "\n",
    "# Pivoteo dinámico usando pandas\n",
    "pivoted_df = df_no_duplicates.pivot(index=['id_cita','id_paciente','fecha_atencion','codigo_item', 'tipo_diagnostico'],\n",
    "                                     columns='id_correlativo_lab',\n",
    "                                     values='valor_lab').reset_index()\n",
    "print(pivoted_df)\n",
    "pivoted_df.to_excel('demo.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consulta_sql(conn):  \n",
    "\n",
    "    sql = conn.df(\"\"\" SELECT * FROM maestros.maestro_his_ubigeo_inei_reniec \"\"\")\n",
    "    sql = sql.rename(columns={'id_ubigueo_inei': 'ubigeo'})\n",
    "    return sql\n",
    "ubigeo=consulta_sql(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>NORKA - NIÑO</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Irvin\\Irvin\\Python\\Python-GERESA\\modulos\\pruebas\\../..\\clases\\bd\\conexion2.py:42: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  s = pd.read_sql(sql, con=self.conn)\n"
     ]
    }
   ],
   "source": [
    "#archivo_excel = \"nominal_ninos.xlsx\"\n",
    "doc=\"SELLO ESTADISTICA/Niños agos a nov 6 a 11 meses\"\n",
    "archivo_excel = \"\"\"%s.xlsx\"\"\"%doc\n",
    "\n",
    "df = pd.read_excel(archivo_excel,sheet_name=0)\n",
    "#df['ubigeo'] = df['ubigeo'].astype(str).str.zfill(6)\n",
    "\n",
    "df=df.drop_duplicates(subset=['Nro_Doc'])\n",
    "\n",
    "df = df.rename(columns={'Nro_Doc': 'nro_doc'})\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "# Convierte los DNIs a una lista\n",
    "dnis = df['nro_doc'].tolist()\n",
    "# Convierte los DNIs en una cadena separada por comas para usar en la consulta SQL\n",
    "numeros_dni_str = ','.join([\"'\" + str(dni) + \"'\" for dni in dnis])\n",
    "\n",
    "# Crea la consulta SQL con una cláusula WHERE para filtrar por los DNIs\n",
    "# Consulta SQL con los números de DNI\n",
    "sql = f\"\"\"SELECT t.numero_documento as nro_doc,t.rn as his  FROM (\n",
    "SELECT\n",
    "   nt.numero_documento, \n",
    "    ROW_NUMBER() OVER (PARTITION BY nt.numero_documento ORDER BY nt.fecha_atencion ) AS rn\n",
    "FROM\n",
    "    maestros.nominal_trama2 nt\n",
    "WHERE\n",
    "    nt.codigo_item = 'C0010'\n",
    "    AND nt.lab1 = 'ALI'\n",
    "    AND nt.lab2 = 'GL'\n",
    "    AND nt.mes in(8,9,10,11,12)\n",
    "    AND nt.numero_documento IN ({numeros_dni_str}) )t WHERE t.rn=1 \"\"\" \n",
    "      \n",
    "ninio=conn.df(sql)\n",
    "\n",
    "#######################################################################################################\n",
    "\n",
    "ninio['nro_doc'] = ninio['nro_doc'].astype(int)\n",
    "\n",
    "df=df.merge(ninio, how='left', on=['nro_doc'])\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "#archivo_excel = \"nominal_ninos.xlsx\"\n",
    "doc=\"SELLO ESTADISTICA/NOMINA DE NIÑOS Y GESTANTES CONSOLIDADO 14.12.23\"\n",
    "archivo_excel = \"\"\"%s.xlsx\"\"\"%doc\n",
    "\n",
    "df2 = pd.read_excel(archivo_excel,sheet_name=0)\n",
    "df2=df2.drop_duplicates(subset=['N° DNI'])\n",
    "\n",
    "df2 = df2.rename(columns={'N° DNI': 'nro_doc'})\n",
    "df2 = df2.drop(['PROVINCIA', 'DISTRITO','Nombre y Apellidos','FECHA DE NACIMIENTO','EDAD'\t], axis=1)\n",
    "df2['numerador'] = 1\n",
    "\n",
    "df=df.merge(df2, how='left', on=['nro_doc'])\n",
    "\n",
    "df.to_excel(\"SELLO ESTADISTICA/ESTADISTICA/Niños agos a nov 6 a 11 meses_Final.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>NORKA - GESTANTE</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Irvin\\Irvin\\Python\\Python-GERESA\\modulos\\pruebas\\../..\\clases\\bd\\conexion2.py:42: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  s = pd.read_sql(sql, con=self.conn)\n"
     ]
    }
   ],
   "source": [
    "#archivo_excel = \"nominal_ninos.xlsx\"\n",
    "doc=\"SELLO ESTADISTICA/nomina gestante agost a noviembre\"\n",
    "archivo_excel = \"\"\"%s.xlsx\"\"\"%doc\n",
    "\n",
    "df = pd.read_excel(archivo_excel,sheet_name=0)\n",
    "#df['ubigeo'] = df['ubigeo'].astype(str).str.zfill(6)\n",
    "\n",
    "df=df.drop_duplicates(subset=['Nro_Doc'])\n",
    "df = df.rename(columns={'Nro_Doc': 'nro_doc'})\n",
    "##############################################################################################\n",
    "\n",
    "# Convierte los DNIs a una lista\n",
    "dnis = df['nro_doc'].tolist()\n",
    "# Convierte los DNIs en una cadena separada por comas para usar en la consulta SQL\n",
    "numeros_dni_str = ','.join([\"'\" + str(dni) + \"'\" for dni in dnis])\n",
    "\n",
    "# Crea la consulta SQL con una cláusula WHERE para filtrar por los DNIs\n",
    "# Consulta SQL con los números de DNI\n",
    "sql = f\"\"\"SELECT t.numero_documento as nro_doc,t.rn as his FROM (\n",
    "SELECT\n",
    "   nt.numero_documento, nt.codigo_item , nt.id_otra_condicion, nt.lab1 , nt.lab2 ,\n",
    "    ROW_NUMBER() OVER (PARTITION BY nt.numero_documento ORDER BY nt.fecha_atencion ) AS rn\n",
    "FROM\n",
    "    maestros.nominal_trama2 nt  \n",
    "WHERE\n",
    "    nt.codigo_item = 'C0010'\n",
    " AND nt.lab1 = 'ALI'\n",
    "    AND nt.lab2 = 'GL'\n",
    "    AND nt.mes in(8,9,10,11,12)\n",
    "    AND nt.anio =2023\n",
    "    AND nt.id_otra_condicion =1\n",
    "    AND nt.numero_documento in ({numeros_dni_str})   \n",
    "    ) t WHERE t.rn=1 \"\"\"       \n",
    "\n",
    "gestante=conn.df(sql)\n",
    "\n",
    "gestante['nro_doc'] = gestante['nro_doc'].astype(int)\n",
    "\n",
    "df=df.merge(gestante, how='left', on=['nro_doc'])\n",
    "\n",
    "#######################################################################################################\n",
    "\n",
    "#archivo_excel = \"nominal_ninos.xlsx\"\n",
    "doc=\"SELLO ESTADISTICA/NOMINA DE NIÑOS Y GESTANTES CONSOLIDADO 14.12.23\"\n",
    "archivo_excel = \"\"\"%s.xlsx\"\"\"%doc\n",
    "\n",
    "df2 = pd.read_excel(archivo_excel,sheet_name=1)\n",
    "df2 = df2.rename(columns={'N° DNI': 'nro_doc'})\n",
    "df2=df2.drop_duplicates(subset=['nro_doc'])\n",
    "\n",
    "columnas_a_conservar = ['nro_doc', ]\n",
    "# Eliminar todas las columnas excepto las especificadas en columnas_a_conservar\n",
    "df2.drop(df2.columns.difference(columnas_a_conservar), axis=1, inplace=True)\n",
    "\n",
    "df2['numerador'] = 1\n",
    "\n",
    "df=df.merge(df2, how='left', on=['nro_doc'])\n",
    "\n",
    "df.to_excel(\"SELLO ESTADISTICA/ESTADISTICA/nomina gestante agost a noviembre.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_excel(archivo_excel,sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko\n",
    "\n",
    "# Configuramos los datos de conexión\n",
    "#host = \"sftp://carga.minsa.gob.pe\"\n",
    "host = \"181.177.250.128\"\n",
    "port = 22\n",
    "username = \"usr_dhr_008\"\n",
    "password = \"X3veTg8z62R74J\"\n",
    "\n",
    "# Creamos el objeto SSHClient\n",
    "client = paramiko.SSHClient()\n",
    "client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "client.connect(host, port, username, password)\n",
    "\n",
    "# Creamos el objeto SFTPClient\n",
    "sftp = client.open_sftp()\n",
    "\n",
    "# Descargamos el archivo\n",
    "filename = \"/data_cvs_nominal/2023/\"\n",
    "local_path = \"C:/Users/IRVIN/Downloads/his/\"\n",
    "sftp.get(filename, local_path)\n",
    "\n",
    "# Cerramos la conexión\n",
    "sftp.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko\n",
    "import os\n",
    "\n",
    "def download_files_sftp(hostname, port, username, password, remote_path, local_path):\n",
    "    try:\n",
    "        # Crear el objeto SSHClient\n",
    "        client = paramiko.SSHClient()\n",
    "        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "\n",
    "        # Conectar al servidor SFTP\n",
    "        client.connect(hostname, port, username, password)\n",
    "\n",
    "        # Crear el objeto SFTPClient\n",
    "        sftp = client.open_sftp()\n",
    "\n",
    "        # Verificar si la ruta local existe, si no, crearla\n",
    "        if not os.path.exists(local_path):\n",
    "            os.makedirs(local_path)\n",
    "\n",
    "        # Listar archivos remotos en el directorio\n",
    "        remote_files = sftp.listdir(remote_path)\n",
    "\n",
    "        # Descargar cada archivo remoto\n",
    "        for remote_file in remote_files:\n",
    "            remote_file_path = os.path.join(remote_path, remote_file)\n",
    "            local_file_path = os.path.join(local_path, remote_file)\n",
    "            sftp.get(remote_file_path, local_file_path)\n",
    "\n",
    "        print(\"Descarga completa.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la descarga: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # Cerrar la conexión\n",
    "        if sftp:\n",
    "            sftp.close()\n",
    "        client.close()\n",
    "\n",
    "# Configuramos los datos de conexión\n",
    "host = \"181.177.250.128\"\n",
    "port = 22\n",
    "username = \"usr_dhr_008\"\n",
    "password = \"X3veTg8z62R74J\"\n",
    "\n",
    "# Ruta remota y local\n",
    "remote_directory = \"/data_cvs_nominal/2023/\"\n",
    "local_directory = \"C:/Users/IRVIN/Downloads/his/\"\n",
    "\n",
    "# Llamar a la función para descargar archivos\n",
    "download_files_sftp(host, port, username, password, remote_directory, local_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "archivo_excel = 'D:\\Irvin\\Anemia\\Capacitacion\\Curso Procesamiento Bases His Cusco-Puno-Piura\\Materiales de consulta\\RENAES - Taller.xlsx'\n",
    "datos = pd.read_excel(archivo_excel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.columns = datos.columns.str.lower()\n",
    "conn.insert_df(datos, 'renaes_altitud_eess','public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.1.7\n",
      "postgres\n",
      "213141\n",
      "irvin_hisminsa\n",
      "5432\n"
     ]
    }
   ],
   "source": [
    "from decouple import config\n",
    "print (config('DB_HOST'))\n",
    "print (config('DB_USER'))\n",
    "print (config('DB_PASSWORD'))\n",
    "print (config('DB_DATABASE'))\n",
    "print (config('DB_PORT'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
